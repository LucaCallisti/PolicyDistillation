{"Teacher_training/losses/entropy":0.6692057847976685,"_timestamp":1.762375353343265e+09,"Teacher_training/video":{"_type":"video-file","sha256":"32ddd7db6053ec43f03f805a562de9fad7e3e142c8d0aff9fbc36fc3eb033038","size":604619,"path":"media/videos/Teacher_training/video_9977856_32ddd7db6053ec43f03f.mp4","caption":"rl-video-episode-638.mp4"},"iteration":610,"Teacher_training/charts/SPS":81,"_wandb":{"runtime":122022},"Teacher_training/losses/Entropy_coef":2.175047293291357e-05,"Teacher_training/charts/learning_rate":0.0001,"Teacher_training/charts/N times avg reward >= target":7,"Teacher_training/losses/value_loss":86.55293273925781,"Teacher_training/losses/approx_kl":0.028670914471149445,"Teacher_training/chart/Average_reward":313.49005126953125,"Teacher_training/losses/old_approx_kl":0.05973891168832779,"_step":9994240,"_runtime":122022.559418145,"Teacher_training/losses/policy_loss":-5.221553146839142e-05,"Teacher_training/losses/explained_variance":0.9407750368118286,"Teacher_training/losses/clipfrac":0.147308349609375}