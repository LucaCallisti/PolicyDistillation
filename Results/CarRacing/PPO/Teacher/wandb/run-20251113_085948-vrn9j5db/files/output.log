Start training...
Warning: Ratio not close to 1 at first update! elements differ. 0.01838505268096924 max diff.
Sanity check for NaNs in model parameters, iteration: 1
Sanity check - CNN params sum: 400.6163112649613
Sanity check - critic params sum: -20.875967293849953
Sanity check - actor_backbone params sum: 8.447970941662788
Sanity check - mu_layer params sum: 0.058175182435661554
Sanity check - log_std_param params sum: -2.164954073727131
[1/2000] AvgRew: nan
/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at /home/l.callisti/Distillation_LunarLander/Final_pipeline/Results/CarRacing/PPO/Teacher/videos/PPO_CarRacing_Teacher_BatchNorm folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
Finished with reward: -46.5, Reward per episode: [ -29.6  -43.9  -21.1  -49.6  -36.2 -123.9  -22.1  -58.9  -38.6  -41. ]
Warning: Ratio not close to 1 at first update! elements differ. 0.7570995092391968 max diff.
Sanity check for NaNs in model parameters, iteration: 2
Sanity check - CNN params sum: 342.97808779590196
Sanity check - critic params sum: -23.11768166764523
Sanity check - actor_backbone params sum: 4.573150850832462
Sanity check - mu_layer params sum: 0.14173900615423918
Sanity check - log_std_param params sum: -2.396721661090851
[2/2000] AvgRew: nan
Warning: Ratio not close to 1 at first update! elements differ. 1.4007930755615234 max diff.
Sanity check for NaNs in model parameters, iteration: 3
Sanity check - CNN params sum: 172.18764709942775
Sanity check - critic params sum: -25.49043978890404
Sanity check - actor_backbone params sum: 6.021170036867261
Sanity check - mu_layer params sum: 0.07851941557601094
Sanity check - log_std_param params sum: -2.517828017473221
[3/2000] AvgRew: -26.95
Warning: Ratio not close to 1 at first update! elements differ. 0.4801417589187622 max diff.
Sanity check for NaNs in model parameters, iteration: 4
Sanity check - CNN params sum: -5.566482419175941
Sanity check - critic params sum: -25.24526438047178
Sanity check - actor_backbone params sum: 4.265356861054897
Sanity check - mu_layer params sum: 0.010484847240149975
Sanity check - log_std_param params sum: -2.6858911514282227
[4/2000] AvgRew: nan
Warning: Ratio not close to 1 at first update! elements differ. 2.271042823791504 max diff.
Sanity check for NaNs in model parameters, iteration: 5
Sanity check - CNN params sum: -136.57778564692626
Sanity check - critic params sum: -24.458966942038387
Sanity check - actor_backbone params sum: 2.04703751206398
Sanity check - mu_layer params sum: 0.029796471819281578
Sanity check - log_std_param params sum: -2.8655319809913635
[5/2000] AvgRew: -26.37
Warning: Ratio not close to 1 at first update! elements differ. 1.2569754123687744 max diff.
Sanity check for NaNs in model parameters, iteration: 6
Sanity check - CNN params sum: -297.04345973632394
Sanity check - critic params sum: -22.969661129405722
Sanity check - actor_backbone params sum: 1.331551417708397
Sanity check - mu_layer params sum: -0.0832293126732111
Sanity check - log_std_param params sum: -2.881710708141327
[6/2000] AvgRew: nan
Warning: Ratio not close to 1 at first update! elements differ. 2.2879514694213867 max diff.
Sanity check for NaNs in model parameters, iteration: 7
Sanity check - CNN params sum: -373.0780516130228
Sanity check - critic params sum: -22.678801845759153
Sanity check - actor_backbone params sum: 2.1782386749982834
Sanity check - mu_layer params sum: -0.15262005757540464
Sanity check - log_std_param params sum: -3.009200930595398
[7/2000] AvgRew: -26.42
Warning: Ratio not close to 1 at first update! elements differ. 1.9438574314117432 max diff.
Sanity check for NaNs in model parameters, iteration: 8
Sanity check - CNN params sum: -524.7730300924754
Sanity check - critic params sum: -20.863471708260477
Sanity check - actor_backbone params sum: 0.5794146955013275
Sanity check - mu_layer params sum: -0.16961396299302578
Sanity check - log_std_param params sum: -3.0343079566955566
[8/2000] AvgRew: nan
Warning: Ratio not close to 1 at first update! elements differ. 2.241712808609009 max diff.
Sanity check for NaNs in model parameters, iteration: 9
Sanity check - CNN params sum: -510.07497311061525
Sanity check - critic params sum: -24.803149417042732
Sanity check - actor_backbone params sum: 3.07873672246933
Sanity check - mu_layer params sum: -0.08863000199198723
Sanity check - log_std_param params sum: -3.271390676498413
[9/2000] AvgRew: -23.71
Warning: Ratio not close to 1 at first update! elements differ. 7.582243919372559 max diff.
> /home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py(178)get_action()
-> if self.deterministic:
*** AttributeError: 'Agent' object has no attribute 'agent'
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor(True, device='cuda:4')
tensor([[[[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],


        [[[0.4000, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.4000, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.3960, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.4000, 0.3960, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.4000, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.3960, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.4000, 0.3960, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.4000, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.4000, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.4000, 0.3960, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.4000, 0.3960, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          [0.4000, 0.3921, 0.3921,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],


        [[[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],


        ...,


        [[[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],


        [[[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],


        [[[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          [0.6269, 0.6269, 0.6269,  ..., 0.6269, 0.6269, 0.6269],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],
       device='cuda:4')
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:4',
       grad_fn=<TanhBackward0>)
torch.Size([256, 4, 96, 96])
Sequential(
  (0): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (5): ReLU(inplace=True)
  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (7): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (9): ReLU(inplace=True)
  (10): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (12): ReLU(inplace=True)
  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (14): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))
  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (16): ReLU(inplace=True)
  (17): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))
  (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (19): ReLU(inplace=True)
  (20): AdaptiveAvgPool2d(output_size=1)
)
Traceback (most recent call last):
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 116, in <module>
    Train_teacher()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 112, in Train_teacher
    PPO_trainer.train()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 319, in train
    advantages, returns = self.compute_gae(next_value)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 199, in ppo_update
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py", line 210, in get_action_and_value
    action, log_prob, entropy = self.get_action(x, action)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py", line 178, in get_action
    if self.deterministic:
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py", line 178, in get_action
    if self.deterministic:
  File "/usr/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
