Start training...
[INFO] Number of trainable parameters: -19.06790542602539
Traceback (most recent call last):
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 110, in <module>
    Train_teacher()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 106, in Train_teacher
    PPO_trainer.train()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 292, in train
    avg_rew, reward_episodes = self.collect_rollouts()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 145, in collect_rollouts
    action, logprob, _, value = self.agent.get_action_and_value(input_)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py", line 206, in get_action_and_value
    action, log_prob, entropy = self.get_action(x, action)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py", line 150, in get_action
    x = self.get_backbone(x)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/Models.py", line 136, in get_backbone
    x = self.cnn_backbone(x)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/modules/container.py", line 240, in forward
    input = module(input)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/modules/pooling.py", line 213, in forward
    return F.max_pool2d(
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/_jit_internal.py", line 622, in fn
    return if_false(*args, **kwargs)
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/nn/functional.py", line 830, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 7 has a total capacity of 39.38 GiB of which 11.81 MiB is free. Process 3230368 has 502.00 MiB memory in use. Including non-PyTorch memory, this process has 38.87 GiB memory in use. Of the allocated memory 36.40 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
