Start training...
Warning: Ratio not close to 1 at first update! elements differ. 1.0 max diff.
Sanity check for NaNs in model parameters, iteration: 1
Sanity check - CNN params sum: 329.05441223776586
Sanity check - critic params sum: -20.304690871449566
Sanity check - actor_backbone params sum: 35.37127527594566
Sanity check - mu_layer params sum: 0.014630310237407684
Sanity check - log_std_param params sum: -4.333768248558044
[1/2000] AvgRew: nan
/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at /home/l.callisti/Distillation_LunarLander/Final_pipeline/Results/CarRacing/PPO/Teacher/videos/PPO_CarRacing_Teacher_BatchNorm folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
Finished with reward: -17.7, Reward per episode: [ -7.4 -24.1  -6.8 -17.3 -16.1  -7.1  -9.8 -32.6 -24.2 -31.1]
Warning: Ratio not close to 1 at first update! elements differ. inf max diff.
/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: Error detected in ExpBackward0. Traceback of forward call that caused the error:
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 116, in <module>
    Train_teacher()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 112, in Train_teacher
    PPO_trainer.train()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 332, in train
    logs = self.ppo_update(advantages, returns)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 203, in ppo_update
    ratio = logratio.exp()
 (Triggered internally at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:122.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Traceback (most recent call last):
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 116, in <module>
    Train_teacher()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/CarRacing.py", line 112, in Train_teacher
    PPO_trainer.train()
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 332, in train
    logs = self.ppo_update(advantages, returns)
  File "/home/l.callisti/Distillation_LunarLander/Final_pipeline/PPO.py", line 250, in ppo_update
    loss.backward()
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/l.callisti/Distillation/distillation/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Function 'ExpBackward0' returned nan values in its 0th output.
